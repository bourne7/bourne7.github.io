# HyperLogLog算法

2019-02-18

> 来源 [http://www.rainybowe.com/blog/2017/07/13/神奇的HyperLogLog算法/index.html](http://www.rainybowe.com/blog/2017/07/13/神奇的HyperLogLog算法/index.html)

这篇文章写得非常不错。我总结一下就是：如果需要对所有不重复数据进行非常准确的统计，来得到所有不重复数据的个数，那么必然有一个可以容纳不重复数数据的数据结构存在，无论基数统计还是 bitmap 都是免不了大量数据的读写。实际上我们只需要得到一个数量就行，比如 “某个大型网站一天内有多少独立IP访问过”，这样的请求。在这种情况下，HyperLogLog 就非常的实用了。

## 概率论里面的伯努利过程

假设我们每抛一次硬币，都记录下1或者0，1代表正面，0代表反面，那么我们抛n次硬币，就会写下一个长度为n的数字。从左边往右边看，第一个1出现的地方和抛硬币的次数是有很明显的关联的：

> 如果抛硬币的时候，第一次出现正面的位置越靠后，那么我们抛硬币的总的次数就会更多。

所以利用这个，我们可以先将IP地址做哈希运算，比如得到一个128bit的数字，然后每来一个IP，我们就更新这个 128bit的数字，只用记下来左边第一个1的位数的最大值就行了，那么我们用来保存的空间只用了 1 byte。。。却可以大致估算出抛的次数了。所以这里可以总结为：

> 每次接受一个新的IP，就等于做了一次抛 128 次硬币的实验。

但是这个可能会导致结果有几倍甚至几十倍的误差，因为越靠近1的那几次波动，产生的干扰就越大。为了摆脱这种误差，可以采用多次抛硬币的方式，对同一个IP可以算多次不同的哈希值，比如100次，然后使用平均数作为本线程的哈希值，这样能大大减少误差到很低的范围。

